{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import glob\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from unet import UNet\n",
    "import imutils\n",
    "import pytorch_ssim\n",
    "import tqdm\n",
    "from IPython.display import HTML,display,clear_output\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import timm\n",
    "import datetime\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_faces(torch.utils.data.Dataset):\n",
    "    def __init__(self, fileName, transform_main=None):\n",
    "        self.fileList = glob.glob(fileName + \"*\")\n",
    "        self.transform_main = transform_main\n",
    "\n",
    "    def __len__(self):\n",
    "        output = len(self.fileList)\n",
    "        return output\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.fileList[idx])\n",
    "        try:\n",
    "            img = self.transform_main(img)\n",
    "        except:\n",
    "            print(self.fileList[idx])\n",
    "\n",
    "        return self.linedraw(img), img\n",
    "\n",
    "    def linedraw(self, x):\n",
    "        transform = torchvision.transforms.Grayscale(3)\n",
    "        x = transform(x)\n",
    "        # 3x3カーネルで膨張1回（膨張はMaxPoolと同じ）\n",
    "        dilated = torch.max_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        # 膨張の前後でL1の差分を取る\n",
    "        diff = torch.abs(x - dilated)\n",
    "        # ネガポジ反転\n",
    "        x = 1.0 - diff\n",
    "        return x\n",
    "\n",
    "\n",
    "def resize_img(img):\n",
    "    \"\"\"\n",
    "    画像をpaddingしながら256x256にする\n",
    "    \"\"\"\n",
    "    height, width, _ = img.shape  # 画像の縦横サイズを取得\n",
    "    diffsize = abs(height - width)\n",
    "    padding_half = int(diffsize / 2)\n",
    "\n",
    "    # 縦長画像→幅を拡張する\n",
    "    if height > width:\n",
    "        padding_img = cv2.copyMakeBorder(\n",
    "            img, 0, 0, padding_half, height - (width + padding_half), cv2.BORDER_CONSTANT, (255, 255, 255)\n",
    "        )\n",
    "    # 横長画像→高さを拡張する\n",
    "    elif width > height:\n",
    "        padding_img = cv2.copyMakeBorder(\n",
    "            img, padding_half, width - (height + padding_half), 0, 0, cv2.BORDER_CONSTANT, (255, 255, 255)\n",
    "        )\n",
    "    else:\n",
    "        padding_img = img\n",
    "    # 最後にリサイズ\n",
    "    return imutils.resize(padding_img, width=64)\n",
    "\n",
    "\n",
    "def cvfunc(img):\n",
    "    img = img[:, :, ::-1]\n",
    "    img = resize_img(img)\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    return PIL.Image.fromarray(img)\n",
    "\n",
    "\n",
    "def show_tensor(input_image_tensor, f):\n",
    "    writer.add_image(tag=\"img\",img_tensor=input_image_tensor,global_step=f)\n",
    "    #img = input_image_tensor.to(\"cpu\").detach().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    # img = img.astype(np.uint8)[0,0,:,:]\n",
    "    #plt.imshow(img)\n",
    "    #plt.savefig(f\"res\\\\test_{f}.png\")\n",
    "    # plt.show()\n",
    "def show_tensor2(input_image_tensor):\n",
    "    #writer.add_image(tag=\"img\",img_tensor=input_image_tensor,global_step=f)\n",
    "    img = input_image_tensor.to(\"cpu\").detach().numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(img)\n",
    "    #plt.savefig(f\"res\\\\test_{f}.png\")\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Lambda(cvfunc),\n",
    "        torchvision.transforms.RandomRotation(degrees=90, fill=(255, 255, 255)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        #テンソル化はできるだけ最後のほうがいい\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "linedataset = dataset_faces(\"image\\\\\", transform)\n",
    "print(len(linedataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(linedataset, [int(len(linedataset)*0.8), len(linedataset)-int(len(linedataset)*0.8)])\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "# モデル定義\n",
    "model = UNet(3, 3)\n",
    "# デバイスモデル設定\n",
    "#\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 損失関数,分類問題のためクロスエントロピー損失関数を利用\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "#criterion = torch.nn.L1Loss()\n",
    "criterion =pytorch_ssim.SSIM(window_size = 11)\n",
    "\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = CosineLRScheduler(optimizer, t_initial=100, lr_min=1e-6, \n",
    "                                  warmup_t=3, warmup_lr_init=1e-6, warmup_prefix=True)\n",
    "EPOCHS = 10000\n",
    "#a, b = next(iter(train_loader))\n",
    "#writer.add_graph(model, a)\n",
    "#print(a.shape, b.shape)\n",
    "\n",
    "os.makedirs(\"res\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    writer.add_image(tag=\"img/l\",img_tensor=a[0],global_step=0)\n",
    "    writer.add_image(tag=\"img/v\",img_tensor=b[0],global_step=0)\n",
    "    show_tensor2(torchvision.utils.make_grid(torch.cat([a, b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h1>～機械学習 学習前レポート～</h1>\n",
       "    <h3>2022年12月01日(Thursday) 00:44:00</h3><table>\n",
       "\t<tbody>\n",
       "\t\t<tr>\n",
       "<td colspan=\"2\">学習全体</td>\n",
       "\t\t</tr>\n",
       "\t\t<tr>\n",
       "\t\t\t<td>デバイス名</td>\n",
       "\t\t\t<td>cuda:0</td>\n",
       "\t\t</tr>\n",
       "\t\t<tr>\n",
       "\t\t\t<td>学習ネットワーク名</td>\n",
       "\t\t\t<td>UNet</td>\n",
       "\t\t</tr>\n",
       "\t\t<tr>\n",
       "\t\t\t<td>損失関数</td>\n",
       "\t\t\t<td>SSIM</td>\n",
       "\t\t</tr>\n",
       "\t\t<tr>\n",
       "\t\t\t<td>最適化関数</td>\n",
       "\t\t\t<td>Adam  学習率 :0.001</td>\n",
       "\t\t</tr>\n",
       "        <tr>\n",
       "\t\t\t<td>スケジューラ</td>\n",
       "\t\t\t<td>CosineLRScheduler</td>\n",
       "\t\t</tr>\n",
       "\t\t<tr>\n",
       "\t\t\t<td>総エポック数</td>\n",
       "\t\t\t<td>10000</td>\n",
       "\t\t</tr>\n",
       "        \n",
       "\t\t<tr>\n",
       "\t\t\t<td>tensorBoardパス</td>\n",
       "\t\t\t<td>runs/fashion_mnist_experiment_1</td>\n",
       "\t\t</tr>\n",
       "\t</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "today = now.strftime('%Y年%m月%d日(%A) %H:%M:%S')\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<h1>～機械学習 学習前レポート～</h1>\n",
    "    <h3>{today}</h3><table>\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "<td colspan=\"2\">学習全体レポート</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>デバイス名</td>\n",
    "\t\t\t<td>{device}</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>学習ネットワーク名</td>\n",
    "\t\t\t<td>{model.__class__.__name__}</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>損失関数</td>\n",
    "\t\t\t<td>{criterion.__class__.__name__}</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>最適化関数</td>\n",
    "\t\t\t<td>{optimizer.__class__.__name__}  学習率 :{optimizer.defaults[\"lr\"]}</td>\n",
    "\t\t</tr>\n",
    "        <tr>\n",
    "\t\t\t<td>スケジューラ</td>\n",
    "\t\t\t<td>{scheduler.__class__.__name__}</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>総エポック数</td>\n",
    "\t\t\t<td>{EPOCHS}</td>\n",
    "\t\t</tr>\n",
    "        \n",
    "\t\t<tr>\n",
    "\t\t\t<td>tensorBoardパス</td>\n",
    "\t\t\t<td>{writer.log_dir}</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit(model,device,criterion,optimizer,scheduler,EPOCHS,writer):\n",
    "    writer.add_text(tag=\"discription\",text_string=f\"# Total Epoch : {EPOCHS}  \\nNet name{model.__class__.__name__}\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        display(HTML(f\"<h1>Now EPOCH : {epoch}/{EPOCHS}</h1><br>\"))\n",
    "        model.train()  # モデルを学習モードにしてGPUに転送（重要）\n",
    "        model.to(device)\n",
    "        trainloss=0\n",
    "        valiloss=0\n",
    "\n",
    "        for batch in tqdm.auto.tqdm(train_loader,desc=\"train\"):\n",
    "            optimizer.zero_grad()  # 必須\n",
    "            # image ,label = batch #(batch_size, channel, size, size)\n",
    "            image, label = batch\n",
    "\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)  # dtype=torch.long\n",
    "\n",
    "            preds = model(image)  # (batch_size, num_class)\n",
    "            # print(preds.dtype)\n",
    "            loss = 1-criterion(preds.to(\"cpu\", dtype=torch.float), label.to(\"cpu\", dtype=torch.float))  # 必須\n",
    "            loss.backward()  # 必須\n",
    "            optimizer.step()  # 必須\n",
    "            trainloss=trainloss+loss.item()\n",
    "        scheduler.step(epoch)\n",
    "        \n",
    "        #writer.add_scalar(\"train loss\",trainloss/len(train_loader),epoch)\n",
    "        model.eval()  # 評価モードにする\n",
    "\n",
    "        with torch.no_grad():  # 必須\n",
    "            for batch in tqdm.auto.tqdm(val_loader,desc=\"valid\"):\n",
    "                image, label = batch  # (batch_size, channel, size, size)\n",
    "\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                preds = model(image)\n",
    "\n",
    "                loss = 1-criterion(preds.to(\"cpu\", dtype=torch.float), label.to(\"cpu\", dtype=torch.float))  # 必須\n",
    "                valiloss=valiloss+loss.item()\n",
    "            writer.add_scalars(\"loss\",{\"val_loss\":valiloss/len(val_loader),\"train_loss\":trainloss/len(train_loader)},epoch)\n",
    "\n",
    "        #if epoch % 10 == 0:\n",
    "        show_tensor(torchvision.utils.make_grid(torch.cat([image, label, preds])), epoch)\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "            #exit()\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Now EPOCH : 1001/10000</h1><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc7b5e5cd9544a1ad5eccafaa9b176d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mセル6 を c:\\Users\\deepfake\\Desktop\\全自動彩色\\Fully-automatic-coloring\\notebook.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/deepfake/Desktop/%E5%85%A8%E8%87%AA%E5%8B%95%E5%BD%A9%E8%89%B2/Fully-automatic-coloring/notebook.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fit(model,device,criterion,optimizer,scheduler,EPOCHS,writer)\n",
      "\u001b[1;32mセル6 を c:\\Users\\deepfake\\Desktop\\全自動彩色\\Fully-automatic-coloring\\notebook.ipynb\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, device, criterion, optimizer, scheduler, EPOCHS, writer)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deepfake/Desktop/%E5%85%A8%E8%87%AA%E5%8B%95%E5%BD%A9%E8%89%B2/Fully-automatic-coloring/notebook.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# print(preds.dtype)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deepfake/Desktop/%E5%85%A8%E8%87%AA%E5%8B%95%E5%BD%A9%E8%89%B2/Fully-automatic-coloring/notebook.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m-\u001b[39mcriterion(preds\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat), label\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat))  \u001b[39m# 必須\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/deepfake/Desktop/%E5%85%A8%E8%87%AA%E5%8B%95%E5%BD%A9%E8%89%B2/Fully-automatic-coloring/notebook.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()  \u001b[39m# 必須\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deepfake/Desktop/%E5%85%A8%E8%87%AA%E5%8B%95%E5%BD%A9%E8%89%B2/Fully-automatic-coloring/notebook.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()  \u001b[39m# 必須\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/deepfake/Desktop/%E5%85%A8%E8%87%AA%E5%8B%95%E5%BD%A9%E8%89%B2/Fully-automatic-coloring/notebook.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m trainloss\u001b[39m=\u001b[39mtrainloss\u001b[39m+\u001b[39mloss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\deepfake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\deepfake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(model,device,criterion,optimizer,scheduler,EPOCHS,writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "83c92f34d168007d65a8d5703b875461caa72e75549f0e5265fd3248e0e496ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
